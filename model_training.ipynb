{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chest X-Ray Model Training & Analysis\n",
                "\n",
                "This notebook covers:\n",
                "1. Data Loading\n",
                "2. Model Training (CheXNet) with Resume Capability\n",
                "3. Raw Probability Outputs\n",
                "4. Batch Predictions\n",
                "5. Visual Explanation (Grad-CAM)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DEBUG CELL: Check Environment\n",
                "import sys\n",
                "import torch\n",
                "print(f\"Python Executable: {sys.executable}\")\n",
                "print(f\"PyTorch Version: {torch.__version__}\")\n",
                "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "import torch\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from torch.utils.data import DataLoader\n",
                "from torchvision import transforms\n",
                "\n",
                "# Ensure we can import from src\n",
                "# Append 'chest_xray_detection/src' to path so we can import 'data', 'modeling', etc.\n",
                "sys.path.append(os.path.abspath('chest_xray_detection/src'))\n",
                "\n",
                "try:\n",
                "    from data.dataset import ChestXrayDataset\n",
                "    from modeling.chexnet import CheXNet\n",
                "    from training.trainer import Trainer\n",
                "    from training.evaluate import compute_auc\n",
                "    from interpretability.gradcam import generate_heatmap\n",
                "except ImportError:\n",
                "    # Alternative if running from 'chest_xray_detection' root\n",
                "    sys.path.append(os.path.abspath('src'))\n",
                "    from data.dataset import ChestXrayDataset\n",
                "    from modeling.chexnet import CheXNet\n",
                "    from training.trainer import train_one_epoch\n",
                "    from training.evaluate import compute_auc\n",
                "    from interpretability.gradcam import generate_heatmap\n",
                "\n",
                "# Configuration\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Using device: {device}')\n",
                "\n",
                "# SPEEDUP: Enable Cudnn Benchmark\n",
                "if torch.cuda.is_available():\n",
                "    torch.backends.cudnn.benchmark = True\n",
                "    print(\"Enabled cuDNN benchmark for speed.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CSV_PATH = 'cleaned_data/dataset_verified.csv'\n",
                "BATCH_SIZE = 32 # Increased to 32 for speed. If OOM, reduce to 16.\n",
                "IMG_SIZE = 224\n",
                "\n",
                "# Define Transforms (Same as training)\n",
                "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "transform_ops = transforms.Compose([\n",
                "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
                "    transforms.ToTensor(),\n",
                "    normalize\n",
                "])\n",
                "\n",
                "# Check if CSV exists\n",
                "if not os.path.exists(CSV_PATH):\n",
                "    print(f\"Error: {CSV_PATH} not found. Please ensure path is correct.\")\n",
                "else:\n",
                "    # Load DataFrame\n",
                "    df = pd.read_csv(CSV_PATH)\n",
                "    # df = df.dropna(subset=['path']) # Verified CSV should be clean\n",
                "    print(f\"Loaded {len(df)} images.\")\n",
                "\n",
                "    # Initialize Dataset\n",
                "    dataset = ChestXrayDataset(df, transform=transform_ops)\n",
                "    \n",
                "    # SPEEDUP: pin_memory=True transfers data to GPU faster\n",
                "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
                "    \n",
                "    print(f\"Classes: {dataset.classes}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_classes = len(dataset.classes)\n",
                "model = CheXNet(num_classes=num_classes, pretrained=True).to(device)\n",
                "print(\"Model initialized.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Setup (Checkpoint Loading)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
                "criterion = torch.nn.BCEWithLogitsLoss()\n",
                "EPOCHS = 3  # Set to desired number\n",
                "\n",
                "# SPEEDUP: Initialize Scaler for Mixed Precision Training\n",
                "scaler = torch.cuda.amp.GradScaler()\n",
                "\n",
                "CHECKPOINT_PATH = 'checkpoints/model_latest.pth'\n",
                "if not os.path.exists('checkpoints'):\n",
                "    os.makedirs('checkpoints')\n",
                "\n",
                "start_epoch = 0\n",
                "\n",
                "# Try to load checkpoint\n",
                "if os.path.exists(CHECKPOINT_PATH):\n",
                "    print(f\"Loading checkpoint from {CHECKPOINT_PATH}...\")\n",
                "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
                "    model.load_state_dict(checkpoint['model_state_dict'])\n",
                "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
                "    \n",
                "    # Load scaler state if available\n",
                "    if 'scaler_state_dict' in checkpoint:\n",
                "        scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
                "        \n",
                "    start_epoch = checkpoint['epoch'] + 1\n",
                "    print(f\"Resuming training from Epoch {start_epoch+1}\")\n",
                "else:\n",
                "    print(\"No checkpoint found. Starting fresh training.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training Loop\n",
                "You can stop the execution of this cell at any time using the Stop button.\n",
                "The model is saved at the end of every epoch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.train()\n",
                "try:\n",
                "    for epoch in range(start_epoch, EPOCHS):\n",
                "        print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
                "        running_loss = 0.0\n",
                "        \n",
                "        # Use tqdm for progress bar if available in notebook environment, else simple print\n",
                "        # The basic print loop is used here for stability\n",
                "        for i, (images, labels) in enumerate(dataloader):\n",
                "            images = images.to(device, non_blocking=True) # non_blocking for speed\n",
                "            labels = labels.to(device, non_blocking=True)\n",
                "            \n",
                "            optimizer.zero_grad(set_to_none=True) # set_to_none is faster than zero_grad()\n",
                "            \n",
                "            # SPEEDUP: Mixed Precision\n",
                "            with torch.cuda.amp.autocast():\n",
                "                outputs = model(images)\n",
                "                loss = criterion(outputs, labels)\n",
                "            \n",
                "            scaler.scale(loss).backward()\n",
                "            scaler.step(optimizer)\n",
                "            scaler.update()\n",
                "            \n",
                "            running_loss += loss.item()\n",
                "            if i % 10 == 0:\n",
                "                print(f\"Batch {i}/{len(dataloader)}, Loss: {loss.item():.4f}\", end='\\r')\n",
                "                \n",
                "        epoch_loss = running_loss/len(dataloader)\n",
                "        print(f\"\\nEpoch {epoch+1} Loss: {epoch_loss:.4f}\")\n",
                "        \n",
                "        # Save checkpoint\n",
                "        torch.save({\n",
                "            'epoch': epoch,\n",
                "            'model_state_dict': model.state_dict(),\n",
                "            'optimizer_state_dict': optimizer.state_dict(),\n",
                "            'scaler_state_dict': scaler.state_dict(),\n",
                "            'loss': epoch_loss,\n",
                "        }, CHECKPOINT_PATH)\n",
                "        print(f\"Checkpoint saved to {CHECKPOINT_PATH}\")\n",
                "\n",
                "except KeyboardInterrupt:\n",
                "    print(\"\\nTraining interrupted by user. Saving current state...\")\n",
                "    # Save state as interrupted\n",
                "    torch.save({\n",
                "        'epoch': epoch - 1 if epoch > 0 else 0,\n",
                "        'model_state_dict': model.state_dict(),\n",
                "        'optimizer_state_dict': optimizer.state_dict(),\n",
                "        'scaler_state_dict': scaler.state_dict(),\n",
                "    }, 'checkpoints/model_interrupted.pth')\n",
                "    print(\"Interrupted state saved. You can rename this to model_latest.pth to resume from start of this epoch approx.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Raw Output Probability (All Diseases Percentage)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.eval()\n",
                "# Get a fresh batch\n",
                "images, labels = next(iter(dataloader))\n",
                "# Need paths to display names, but DataLoader with default collate assumes standard return\n",
                "# Dataset __getitem__ returns (image, label). It doesn't return path.\n",
                "# We can access path via df directly for visualization if needed.\n",
                "# Or modify dataset to return path, but let's stick to indices.\n",
                "\n",
                "images = images.to(device)\n",
                "\n",
                "with torch.no_grad():\n",
                "    outputs = model(images)\n",
                "    probs = torch.sigmoid(outputs).cpu().numpy()\n",
                "\n",
                "# Show for the first image in batch\n",
                "idx = 0\n",
                "print(\"Raw Probabilities:\")\n",
                "for i, class_name in enumerate(dataset.classes):\n",
                "    print(f\"{class_name}: {probs[idx][i]*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Batch Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results = []\n",
                "for i in range(len(images)):\n",
                "    # Get top 3 predictions\n",
                "    p = probs[i]\n",
                "    top3_indices = p.argsort()[-3:][::-1]\n",
                "    top3_preds = [f\"{dataset.classes[j]} ({p[j]*100:.1f}%)\" for j in top3_indices]\n",
                "    \n",
                "    # Ground truth\n",
                "    true_labels_indices = np.where(labels[i].numpy() == 1)[0]\n",
                "    true_labels_names = [dataset.classes[j] for j in true_labels_indices]\n",
                "    if not true_labels_names: \n",
                "        true_labels_names = [\"No Finding\"]\n",
                "        \n",
                "    results.append({\n",
                "        \"True Labels\": \", \".join(true_labels_names),\n",
                "        \"Predictions\": \", \".join(top3_preds)\n",
                "    })\n",
                "\n",
                "df_results = pd.DataFrame(results)\n",
                "display(df_results)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Visual Explanation (Grad-CAM)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Choose an image to visualize (e.g., the first in the batch)\n",
                "target_idx = 0\n",
                "input_img = images[target_idx]\n",
                "# Since we don't have path from dataloader, let's just use a dummy path or reconstruct from df if we mapped it, \n",
                "# but for show_cam_on_image it loads from path. \n",
                "# We can check if generate_heatmap accepts tensor directly or needs path for background.\n",
                "# It takes 'original_img_path' to load and overlay.\n",
                "# Let's workaround: Save the current tensor as temp image to overlay on.\n",
                "\n",
                "from torchvision.utils import save_image\n",
                "# Inverse normalize to save viewable image\n",
                "inv_normalize = transforms.Normalize(\n",
                "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
                "    std=[1/0.229, 1/0.224, 1/0.225]\n",
                ")\n",
                "inv_img = inv_normalize(input_img.cpu())\n",
                "# Clamp\n",
                "inv_img = torch.clamp(inv_img, 0, 1)\n",
                "temp_img_path = 'temp_gradcam_input.png'\n",
                "save_image(inv_img, temp_img_path)\n",
                "\n",
                "# DenseNet121 target layer for Grad-CAM is usually the last dense block features\n",
                "target_layer = model.densenet121.features[-1]\n",
                "\n",
                "print(f\"Generating Grad-CAM...\")\n",
                "generate_heatmap(model, input_img, temp_img_path, target_layer, device=device, save_path='gradcam_result.png')\n",
                "\n",
                "# Display result inline\n",
                "img = plt.imread('gradcam_result.png')\n",
                "plt.figure(figsize=(8,8))\n",
                "plt.imshow(img)\n",
                "plt.axis('off')\n",
                "plt.title(\"Multi-label Grad-CAM\")\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}